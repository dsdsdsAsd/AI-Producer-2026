"""
–£–∑–ª—ã LangGraph –≥—Ä–∞—Ñ–∞.
–ö–∞–∂–¥—ã–π —É–∑–µ–ª –≤—ã–ø–æ–ª–Ω—è–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –≤ –∞–≥–µ–Ω—Ç—Å–∫–æ–π RAG —Å–∏—Å—Ç–µ–º–µ.
"""

from langchain_core.messages import HumanMessage, AIMessage
from langchain_openai import ChatOpenAI
# # from langchain_ollama import ChatOllama

from graph.state import GraphState
from tools.intent_classifier import get_intent_classifier
from tools.rag_retriever import get_rag_retriever
from config.settings import settings
from config.prompts import GENERATOR_SYSTEM_PROMPT
from utils.llm_factory import get_llm
from utils.logger import logger


def strategy_node(state: GraphState) -> GraphState:
    """
    –£–∑–µ–ª —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏: –ø–æ–¥–≥—Ä—É–∂–∞–µ—Ç –ª–∏—á–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –ë–î.
    –≠—Ç–æ –¥–∞–µ—Ç –ò–ò –ø–æ–Ω–∏–º–∞–Ω–∏–µ '–ö—Ç–æ —è', '–ß—Ç–æ –ø—Ä–æ–¥–∞–µ–º', '–ö–∞–∫–∏–µ –∫–µ–π—Å—ã'.
    """
    logger.info("=== Strategy Node ===")
    
    try:
        from database.connection import get_db
        from database.models import UserStrategy
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–µ—Å—Å–∏—é –ë–î
        db_gen = get_db()
        db = next(db_gen)
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é (default —é–∑–µ—Ä)
        strategy = db.query(UserStrategy).filter(UserStrategy.user_id == "default").first()
        
        if strategy:
            # –§–æ—Ä–º–∏—Ä—É–µ–º —á–∏—Ç–∞–µ–º—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è LLM
            strategy_context = f"""
### –≠–¢–ê–õ–û–ù–ù–´–ô –ö–û–ù–¢–ï–ö–°–¢ –≠–ö–°–ü–ï–†–¢–ê (–ö–¢–û –Ø):
{strategy.full_context}

### –°–¢–†–ê–¢–ï–ì–ò–ß–ï–°–ö–ò–ï –î–ê–ù–ù–´–ï:
- –¶–ï–õ–¨: {strategy.goals}
- –ö–ï–ô–°–´: {strategy.cases}
- –¢–†–ò–ì–ì–ï–†–´: {strategy.triggers}
"""
            # –õ–æ–≥–∏–∫–∞ Shorts
            if strategy.shorts_logic:
                sl = strategy.shorts_logic
                if isinstance(sl, str):
                    try: import json; sl = json.loads(sl)
                    except: pass
                
                if isinstance(sl, dict):
                    strategy_context += f"\n### –ü–†–ê–í–ò–õ–ê –í–ê–®–ò–• SHORTS:\n"
                    strategy_context += f"- –°–¢–†–£–ö–¢–£–†–ê: {' -> '.join(sl.get('structure', []))}\n"
                    strategy_context += f"- –ü–†–ò–ú–ï–†–´ –•–£–ö–û–í –î–õ–Ø –ú–û–î–ï–õ–ï–ô: {', '.join(sl.get('hook_examples', []))}\n"
            # –ú–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏—è
            if strategy.monetization:
                m = strategy.monetization
                if isinstance(m, str):
                    try: import json; m = json.loads(m)
                    except: pass
                
                if isinstance(m, dict):
                    strategy_context += f"- –ú–û–ù–ï–¢–ò–ó–ê–¶–ò–Ø: {m.get('product', '–ö—É—Ä—Å')} –∑–∞ {m.get('price', '50k')}\n"
                    strategy_context += f"- –ê–ö–¢–ò–í–´: {', '.join(m.get('assets', []))}\n"

            state["summary"] = (state.get("summary") or "") + "\n" + strategy_context
            logger.info("User strategy successfully loaded into context")
        else:
            logger.info("No user strategy found in DB")
            
    except Exception as e:
        logger.error(f"Error in strategy_node: {e}")
        
    return state


def router_node(state: GraphState) -> GraphState:
    """
    –£–∑–µ–ª –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏: –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞–º–µ—Ä–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    
    Args:
        state: –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≥—Ä–∞—Ñ–∞
        
    Returns:
        GraphState: –û–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å intent
    """
    logger.info("=== Router Node ===")
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    messages = state["messages"]
    if not messages:
        logger.warning("No messages in state")
        state["intent"] = "direct_response"
        return state
    
    last_message = messages[-1]
    user_message = last_message.content if hasattr(last_message, 'content') else str(last_message)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å–æ–æ–±—â–µ–Ω–∏–π)
    chat_history = []
    for msg in messages[-5:]:
        if isinstance(msg, HumanMessage):
            chat_history.append({"role": "user", "content": msg.content})
        elif isinstance(msg, AIMessage):
            chat_history.append({"role": "assistant", "content": msg.content})
    
    # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –Ω–∞–º–µ—Ä–µ–Ω–∏–µ
    classifier = get_intent_classifier()
    intent = classifier.classify(user_message, chat_history)
    
    logger.info(f"Intent classified: {intent}")
    
    # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    state["intent"] = intent
    
    return state


    return state


def summary_node(state: GraphState) -> GraphState:
    """
    –£–∑–µ–ª Summary: –ø–æ–¥–≥—Ä—É–∂–∞–µ—Ç "–ø–∞—Å–ø–æ—Ä—Ç –∫–Ω–∏–≥–∏" (–≥–ª–æ–±–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç).
    –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ò–ò –∑–Ω–∞—Ç—å –æ–±—â–µ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –∫–Ω–∏–≥–∏, —Å–ø–∏—Å–æ–∫ –≥–ª–∞–≤ –∏ —Ç.–¥.
    """
    logger.info("=== Summary Node ===")
    
    # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –ø–∞—Å–ø–æ—Ä—Ç –∫–Ω–∏–≥–∏ –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
    # –î–ª—è –Ω–∞—á–∞–ª–∞ –ø—Ä–æ—Å—Ç–æ —Å–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫—É-–∑–∞–ø—Ä–æ—Å –∫ –ë–î –¥–ª—è –ø–æ–∏—Å–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
    try:
        from database.connection import get_supabase_client
        client = get_supabase_client()
        
        # –ò—â–µ–º —á–∞–Ω–∫ —Å —Ç–∏–ø–æ–º 'summary' –∏–ª–∏ 'passport'
        response = client.table("knowledge_base").select("content").filter("metadata->>type", "eq", "passport").execute()
        
        if response.data and len(response.data) > 0:
            state["summary"] = response.data[0]["content"]
            logger.info("Book passport found and loaded into state")
        else:
            # –ï—Å–ª–∏ –ø–∞—Å–ø–æ—Ä—Ç–∞ –Ω–µ—Ç, –º–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –≤—ã–≤–µ—Å—Ç–∏ —Å–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            logger.info("No passport found in DB")
            state["summary"] = "–ì–ª–æ–±–∞–ª—å–Ω—ã–π –ø–∞—Å–ø–æ—Ä—Ç –∫–Ω–∏–≥–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω. –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã."
            
    except Exception as e:
        logger.error(f"Error in summary_node: {e}")
        state["summary"] = None
        
    return state


def rag_node(state: GraphState) -> GraphState:
    """
    –£–∑–µ–ª RAG: –≤—ã–ø–æ–ª–Ω—è–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.
    
    Args:
        state: –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≥—Ä–∞—Ñ–∞
        
    Returns:
        GraphState: –û–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å context –∏ sources
    """
    logger.info("=== RAG Node ===")
    
    # –ü–æ–ª—É—á–∞–µ–º –∑–∞–ø—Ä–æ—Å –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    messages = state.get("messages", [])
    if not messages:
        logger.warning("No messages in state")
        state["context"] = ""
        state["sources"] = []
        return state
    
    query = messages[-1].content if hasattr(messages[-1], 'content') else str(messages[-1])
    logger.info(f"RAG query: {query[:100]}...")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–µ—Ä—Å–æ–Ω—ã
    persona = state.get("persona")
    filter_metadata = {}
    
    # –§–ò–õ–¨–¢–†: –ò—Å–∫–ª—é—á–∞–µ–º –∫–Ω–∏–≥—É –ø—Ä–æ –ú—É—Ä–∞–¥–æ–≤–∞ (type='book')
    # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—â–µ–º —Ç–æ–ª—å–∫–æ –≤ type='shorts_transcript' –∏–ª–∏ 'velizhanin'
    if persona == "velizhanin":
        filter_metadata = {"author": "Nikolay Velizhanin"}
        logger.info("Using Velizhanin isolation filter")
    elif persona == "esther":
        filter_metadata = {"author": "Esther Hicks"}
        logger.info("Using Esther Hicks isolation filter")
    else:
        # –ï—Å–ª–∏ –ø–µ—Ä—Å–æ–Ω–∞ –Ω–µ –∑–∞–¥–∞–Ω–∞, –∏—â–µ–º –≤–æ –í–°–ï–• —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞—Ö (–≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–∞–µ–º —Ñ–∏–ª—å—Ç—Ä –¥–ª—è —Ç–µ—Å—Ç–∞)
        filter_metadata = {}
        logger.info("üîç Diagnostic mode: searching across all documents without filter")

    # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ (graceful fallback –µ—Å–ª–∏ embeddings –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã)
    try:
        context, sources = retriever.retrieve_and_format(query, filter_metadata=filter_metadata, use_scores=True)
        # –í—Ä–µ–º–µ–Ω–Ω–æ —Å–Ω–∏–∂–∞–µ–º –ø–æ—Ä–æ–≥ –≤—Ä—É—á–Ω—É—é –≤ retriever –µ—Å–ª–∏ –Ω—É–∂–Ω–æ, –Ω–æ –ª—É—á—à–µ –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –≤–µ—Ä–Ω–µ—Ç.
        
        logger.info(f"RAG retrieved {len(sources)} sources")
        if sources:
            logger.info(f"Retrieved sources: {[s.get('chapter', s.get('title', 'unknown')) for s in sources]}")
            scores = [s.get('similarity', 0.0) for s in sources]
            avg_score = sum(scores) / len(scores) if scores else 0.0
            logger.info(f"üìä Avg similarity score: {avg_score:.3f}, Scores: {[f'{s:.3f}' for s in scores]}")
            if avg_score < 0.7:
                logger.warning(f"‚ö†Ô∏è Low quality retrieval! Avg score {avg_score:.3f} < 0.7")
    except Exception as e:
        logger.error(f"‚ùå RAG retrieval failed (embeddings unavailable?): {e}")
        logger.warning("üîÑ Continuing without RAG context ‚Äî will respond directly via LLM")
        context = ""
        sources = []
    
    # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –¥–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    if not context:
        logger.warning("RAG node found no context.")
        context = ""
        sources = []

    state["context"] = context
    state["sources"] = sources
    
    return state


def generator_node(state: GraphState) -> GraphState:
    """
    –£–∑–µ–ª –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: —Å–æ–∑–¥–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.
    
    Args:
        state: –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≥—Ä–∞—Ñ–∞
        
    Returns:
        GraphState: –û–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å –æ—Ç–≤–µ—Ç–æ–º assistant
    """
    logger.info("=== Generator Node ===")
    
    # --- DEBUG LOGGING ---
    context = state.get("context") or ""
    summary = state.get("summary") or ""
    logger.info(f"Context length: {len(context)} chars")
    logger.info(f"Summary length: {len(summary)} chars")
    if context:
        logger.info(f"Context (first 500 chars): {context[:500]}")
    # --- END DEBUG LOGGING ---

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º LLM (OpenAI –∏–ª–∏ Ollama)
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º LLM (OpenAI –∏–ª–∏ Ollama)
    llm = get_llm(temperature=settings.temperature)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
    messages = [{"role": "system", "content": GENERATOR_SYSTEM_PROMPT}]
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ RAG (–µ—Å–ª–∏ –µ—Å—Ç—å)
    if context:
        context_message = {
            "role": "system",
            "content": f"–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:\n\n{context}"
        }
        messages.append(context_message)
    
    # –î–æ–±–∞–≤–ª—è–µ–º "–ø–∞—Å–ø–æ—Ä—Ç" –∫–Ω–∏–≥–∏ (–≥–ª–æ–±–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç)
    if summary:
        summary_message = {
            "role": "system",
            "content": f"–ì–ª–æ–±–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∫–Ω–∏–≥–∏ (–ø–∞—Å–ø–æ—Ä—Ç):\n\n{summary}"
        }
        messages.append(summary_message)
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å —É—á–µ—Ç–æ–º —ç—Ç–∞–ø–∞ –∏ –±–ª—é–ø—Ä–∏–Ω—Ç–∞
    current_stage = state.get("current_stage", 1)
    blueprint = state.get("blueprint", {})
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫—Ä–∞—Ç–∫–∏–π –æ–±–∑–æ—Ä –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
    blueprint_summary = ""
    if blueprint:
        blueprint_summary = "–ù–∞–∫–æ–ø–ª–µ–Ω–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è (ContentBlueprint):\n"
        for stage_num, data in blueprint.items():
            blueprint_summary += f"–≠—Ç–∞–ø {stage_num}: {data}\n"
    else:
        blueprint_summary = "–°—Ç—Ä–∞—Ç–µ–≥–∏—è –µ—â–µ –Ω–µ –Ω–∞—á–∞—Ç–∞. –ú—ã –Ω–∞ –≠–¢–ê–ü–ï 1."

    # –û–±–Ω–æ–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–∞–Ω–Ω—ã–º–∏
    formatted_system_prompt = GENERATOR_SYSTEM_PROMPT.format(
        current_stage=current_stage,
        blueprint_summary=blueprint_summary
    )
    
    # –ó–∞–º–µ–Ω—è–µ–º –ø–µ—Ä–≤—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –Ω–∞ –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π
    messages[0]["content"] = formatted_system_prompt
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π)
    for msg in state["messages"][-10:]:
        if isinstance(msg, HumanMessage):
            messages.append({"role": "user", "content": msg.content})
        elif isinstance(msg, AIMessage):
            messages.append({"role": "assistant", "content": msg.content})
    
    logger.info(f"Final prompt message count: {len(messages)}")
    # Log the system role messages to see context presence
    for m in messages:
        if m["role"] == "system":
            logger.info(f"System message ({len(m['content'])} chars): {m['content'][:200]}...")
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç (–±–µ–∑ streaming –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã, streaming –±—É–¥–µ—Ç –≤ API)
    try:
        logger.info("Invoking LLM...")
        response = llm.invoke(messages)
        answer = response.content
        
        logger.info(f"LLM call successful. Generated answer: {len(answer)} chars")
        
        # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç –Ω–∞ –Ω–∞–ª–∏—á–∏–µ JSON-–¥–∞–Ω–Ω—ã—Ö —Ç–µ–∫—É—â–µ–≥–æ —ç—Ç–∞–ø–∞
        # –ï—Å–ª–∏ –∞–≥–µ–Ω—Ç –≤—ã–¥–∞–ª —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –ø–æ —ç—Ç–∞–ø—É, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –µ–≥–æ –≤ –±–ª—é–ø—Ä–∏–Ω—Ç
        try:
            import re
            import json
            # –ò—â–µ–º JSON –≤ –±–ª–æ–∫–∞—Ö –∫–æ–¥–∞ –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –≤ —Ç–µ–∫—Å—Ç–µ
            json_match = re.search(r"```json\s*(.*?)\s*```", answer, re.DOTALL) or re.search(r"(\{.*?\})", answer, re.DOTALL)
            if json_match:
                stage_data = json.loads(json_match.group(1))
                stage_num = state.get("current_stage", 1)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –±–ª—é–ø—Ä–∏–Ω—Ç
                if "blueprint" not in state or state["blueprint"] is None:
                    state["blueprint"] = {}
                
                state["blueprint"][str(stage_num)] = stage_data
                logger.info(f"‚ú® Stage {stage_num} data saved to blueprint")
                
                # –ï—Å–ª–∏ —ç—Ç–∞–ø –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ, –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É
                if stage_num < 10:
                    state["current_stage"] = stage_num + 1
                    logger.info(f"üöÄ Moving to Stage {state['current_stage']}")
                    
                    # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –º–µ—Ç–∫–∞ –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞ –æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —ç—Ç–∞–ø–∞
                    if "metadata" not in state: state["metadata"] = {}
                    state["metadata"]["last_saved_stage"] = stage_num
        except Exception as e:
            logger.warning(f"Failed to auto-parse stage data: {e}")

        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –≤ messages
        state["messages"].append(AIMessage(content=answer))
        
        if "metadata" not in state:
            state["metadata"] = {}
            
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        state["metadata"]["sources"] = state.get("sources", [])
        state["metadata"]["intent"] = state.get("intent")
        
    except Exception as e:
        logger.error(f"Generation error: {e}")
        # Fallback –æ—Ç–≤–µ—Ç
        error_message = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞."
        state["messages"].append(AIMessage(content=error_message))
    
    return state


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —É–∑–ª–∞ (conditional edge)
def route_question(state: GraphState) -> str:
    """
    –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å–ª–µ–¥—É—é—â–∏–π —É–∑–µ–ª –Ω–∞ –æ—Å–Ω–æ–≤–µ intent.
    
    Args:
        state: –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≥—Ä–∞—Ñ–∞
        
    Returns:
        str: –ù–∞–∑–≤–∞–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ —É–∑–ª–∞
    """
    intent = state.get("intent")
    
    logger.info(f"Routing based on intent: {intent}")
    
    # –í–†–ï–ú–ï–ù–ù–û: –í—Å–µ–≥–¥–∞ –∏–¥–µ–º —á–µ—Ä–µ–∑ RAG –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞
    # –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ —Å–∏—Å—Ç–µ–º–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∑–Ω–∞–Ω–∏—è –í–µ–ª–∏–∂–∞–Ω–∏–Ω–∞
    logger.info("üî• Forcing RAG route for all queries (testing mode)")
    return "rag"
    
    # –û–†–ò–ì–ò–ù–ê–õ–¨–ù–ê–Ø –õ–û–ì–ò–ö–ê (–∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∞):
    # if intent in ["knowledge_base_search", "creative_writing"]:
    #     return "rag"
    # else:
    #     return "generator"

